"""
æ•°æ®åº“è¿ç§»å·¥å…·
å°†ç°æœ‰è§„åˆ™æ•°æ®è½¬æ¢ä¸ºæ–°çš„æ•°æ®åº“æ ¼å¼ï¼Œå¹¶è¿›è¡ŒéªŒè¯

Author: Mapoet
Institution: NUS/STAR
Date: 2025-01-23
License: MIT
"""

import json
import asyncio
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional
import yaml

from .models import (
    CursorRule, RuleType, ContentType, TaskType, ValidationSeverity,
    RuleCondition, RuleApplication, RuleValidation
)
from .database import RuleDatabase, get_rule_database
from .rule_generator import RuleGenerator


class RuleMigration:
    """è§„åˆ™è¿ç§»å·¥å…·"""
    
    def __init__(self):
        self.migration_log: List[Dict[str, Any]] = []
    
    def migrate_legacy_rules(self, legacy_file: Path, output_dir: Path) -> List[CursorRule]:
        """è¿ç§»ä¼ ç»Ÿè§„åˆ™æ–‡ä»¶"""
        print(f"ğŸ”„ å¼€å§‹è¿ç§»è§„åˆ™æ–‡ä»¶: {legacy_file}")
        
        # è¯»å–ä¼ ç»Ÿè§„åˆ™
        try:
            with open(legacy_file, 'r', encoding='utf-8') as f:
                legacy_data = json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–è§„åˆ™æ–‡ä»¶å¤±è´¥: {e}")
            return []
        
        if not isinstance(legacy_data, list):
            legacy_data = [legacy_data]
        
        migrated_rules = []
        for rule_data in legacy_data:
            try:
                migrated_rule = self._convert_legacy_rule(rule_data)
                migrated_rules.append(migrated_rule)
                self.migration_log.append({
                    "rule_id": migrated_rule.rule_id,
                    "status": "success",
                    "message": "æˆåŠŸè¿ç§»"
                })
            except Exception as e:
                self.migration_log.append({
                    "rule_id": rule_data.get("rule_id", "unknown"),
                    "status": "error",
                    "message": f"è¿ç§»å¤±è´¥: {e}"
                })
                print(f"âš ï¸ è¿ç§»è§„åˆ™å¤±è´¥ {rule_data.get('rule_id', 'unknown')}: {e}")
        
        # ä¿å­˜è¿ç§»çš„è§„åˆ™
        if migrated_rules:
            self._save_migrated_rules(migrated_rules, output_dir)
        
        print(f"âœ… è¿ç§»å®Œæˆï¼ŒæˆåŠŸè¿ç§» {len(migrated_rules)} æ¡è§„åˆ™")
        return migrated_rules
    
    def _convert_legacy_rule(self, legacy_data: Dict[str, Any]) -> CursorRule:
        """è½¬æ¢ä¼ ç»Ÿè§„åˆ™æ ¼å¼"""
        # åŸºæœ¬ä¿¡æ¯
        rule_id = legacy_data["rule_id"]
        name = legacy_data["name"]
        description = legacy_data["description"]
        
        # è½¬æ¢è§„åˆ™ç±»å‹
        rule_type = self._convert_rule_type(legacy_data.get("category", "style"))
        
        # è½¬æ¢å†…å®¹ç±»å‹
        content_types = self._convert_content_types(
            legacy_data.get("applicable_to", {}).get("content_types", ["code"])
        )
        
        # è½¬æ¢ä»»åŠ¡ç±»å‹ï¼ˆä»æ ‡ç­¾æ¨æ–­ï¼‰
        task_types = self._infer_task_types(legacy_data.get("tags", []))
        
        # è½¬æ¢è§„åˆ™æ¡ä»¶
        rules = self._convert_rule_conditions(legacy_data.get("rule_content", {}))
        
        # è½¬æ¢åº”ç”¨èŒƒå›´
        applies_to = self._convert_application_scope(legacy_data.get("applicable_to", {}))
        
        # è½¬æ¢éªŒè¯ä¿¡æ¯
        validation = self._convert_validation(legacy_data.get("validation", {}))
        
        # å…ƒæ•°æ®å¤„ç†
        metadata = legacy_data.get("metadata", {})
        version = metadata.get("version", "1.0.0")
        author = metadata.get("author", "Unknown")
        
        # åˆ›å»ºæ—¶é—´
        created_at = datetime.now(timezone.utc)
        if "created_at" in metadata:
            try:
                created_at = datetime.fromisoformat(metadata["created_at"].replace('Z', '+00:00'))
            except:
                pass
        
        # æ›´æ–°æ—¶é—´
        updated_at = datetime.now(timezone.utc)
        if "updated_at" in metadata:
            try:
                updated_at = datetime.fromisoformat(metadata["updated_at"].replace('Z', '+00:00'))
            except:
                pass
        
        return CursorRule(
            rule_id=rule_id,
            name=name,
            description=description,
            version=version,
            author=author,
            created_at=created_at,
            updated_at=updated_at,
            rule_type=rule_type,
            languages=legacy_data.get("applicable_to", {}).get("languages", []),
            domains=legacy_data.get("applicable_to", {}).get("domains", []),
            task_types=task_types,
            content_types=content_types,
            tags=legacy_data.get("tags", []),
            rules=rules,
            applies_to=applies_to,
            validation=validation,
            active=True,
            usage_count=0,
            success_rate=0.0
        )
    
    def _convert_rule_type(self, category: str) -> RuleType:
        """è½¬æ¢è§„åˆ™ç±»å‹"""
        type_mapping = {
            "style": RuleType.STYLE,
            "content": RuleType.CONTENT,
            "semantic": RuleType.CONTENT,
            "performance": RuleType.PERFORMANCE,
            "format": RuleType.FORMAT,
            "security": RuleType.SECURITY
        }
        return type_mapping.get(category.lower(), RuleType.STYLE)
    
    def _convert_content_types(self, legacy_types: List[str]) -> List[ContentType]:
        """è½¬æ¢å†…å®¹ç±»å‹"""
        type_mapping = {
            "code": ContentType.CODE,
            "documentation": ContentType.DOCUMENTATION,
            "data_interface": ContentType.DATA,
            "algorithm": ContentType.ALGORITHM,
            "configuration": ContentType.CONFIGURATION
        }
        
        result = []
        for legacy_type in legacy_types:
            content_type = type_mapping.get(legacy_type.lower())
            if content_type and content_type not in result:
                result.append(content_type)
        
        return result or [ContentType.CODE]
    
    def _infer_task_types(self, tags: List[str]) -> List[TaskType]:
        """ä»æ ‡ç­¾æ¨æ–­ä»»åŠ¡ç±»å‹"""
        task_mapping = {
            "documentation": TaskType.DOCUMENTATION,
            "testing": TaskType.TESTING,
            "refactoring": TaskType.REFACTORING,
            "debugging": TaskType.DEBUGGING,
            "optimization": TaskType.OPTIMIZATION,
            "review": TaskType.CODE_REVIEW
        }
        
        result = []
        for tag in tags:
            task_type = task_mapping.get(tag.lower())
            if task_type and task_type not in result:
                result.append(task_type)
        
        return result
    
    def _convert_rule_conditions(self, rule_content: Dict[str, Any]) -> List[RuleCondition]:
        """è½¬æ¢è§„åˆ™æ¡ä»¶"""
        conditions = []
        
        guideline = rule_content.get("guideline", "")
        examples = rule_content.get("examples", [])
        pattern = rule_content.get("pattern")
        
        # åˆ›å»ºä¸»è¦æ¡ä»¶
        main_condition = RuleCondition(
            condition=rule_content.get("condition", "main_rule"),
            guideline=guideline,
            priority=8,  # é»˜è®¤ä¼˜å…ˆçº§
            examples=examples,
            pattern=pattern
        )
        
        conditions.append(main_condition)
        
        return conditions
    
    def _convert_application_scope(self, applicable_to: Dict[str, Any]) -> RuleApplication:
        """è½¬æ¢åº”ç”¨èŒƒå›´"""
        return RuleApplication(
            file_patterns=applicable_to.get("file_patterns", []),
            exclude_patterns=applicable_to.get("exclude_patterns", []),
            min_file_size=applicable_to.get("min_file_size", 0),
            max_file_size=applicable_to.get("max_file_size", 1000000),
            requires_context=applicable_to.get("requires_context", False)
        )
    
    def _convert_validation(self, validation_data: Dict[str, Any]) -> RuleValidation:
        """è½¬æ¢éªŒè¯ä¿¡æ¯"""
        # è½¬æ¢ä¸¥é‡ç¨‹åº¦
        severity_mapping = {
            "error": ValidationSeverity.ERROR,
            "warning": ValidationSeverity.WARNING,
            "info": ValidationSeverity.INFO
        }
        
        severity = severity_mapping.get(
            validation_data.get("severity", "warning").lower(),
            ValidationSeverity.WARNING
        )
        
        return RuleValidation(
            tools=validation_data.get("tools", []),
            severity=severity,
            auto_fix=validation_data.get("auto_fix", False),
            timeout=validation_data.get("timeout", 30),
            custom_config=validation_data.get("custom_config", {})
        )
    
    def _save_migrated_rules(self, rules: List[CursorRule], output_dir: Path) -> None:
        """ä¿å­˜è¿ç§»çš„è§„åˆ™"""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ä¸ºYAMLæ ¼å¼ï¼ˆæ›´æ˜“è¯»ï¼‰
        migrated_file = output_dir / "migrated_rules.yaml"
        rules_data = [rule.dict() for rule in rules]
        
        with open(migrated_file, 'w', encoding='utf-8') as f:
            yaml.dump(rules_data, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… è¿ç§»çš„è§„åˆ™å·²ä¿å­˜åˆ° {migrated_file}")
        
        # ä¿å­˜è¿ç§»æ—¥å¿—
        log_file = output_dir / "migration_log.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump({
                "migration_date": datetime.now(timezone.utc).isoformat(),
                "total_rules": len(rules),
                "migration_log": self.migration_log
            }, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è¿ç§»æ—¥å¿—å·²ä¿å­˜åˆ° {log_file}")


async def perform_database_migration():
    """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“è¿ç§»"""
    print("ğŸš€ å¼€å§‹è§„åˆ™åº“æ•°æ®åŒ–è¿ç§»...")
    
    # 1. è¿ç§»ç°æœ‰è§„åˆ™
    migration = RuleMigration()
    legacy_file = Path("examples/sample-rules.json")
    output_dir = Path("data/rules/migrated")
    
    migrated_rules = []
    if legacy_file.exists():
        migrated_rules = migration.migrate_legacy_rules(legacy_file, output_dir)
    else:
        print(f"âš ï¸ ä¼ ç»Ÿè§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨: {legacy_file}")
    
    # 2. ç”Ÿæˆæ‰©å±•è§„åˆ™
    print("\nğŸ“š ç”Ÿæˆæ‰©å±•è§„åˆ™åº“...")
    generator = RuleGenerator()
    generated_rules = generator.generate_comprehensive_ruleset()
    
    # ä¿å­˜ç”Ÿæˆçš„è§„åˆ™
    generated_dir = Path("data/rules/generated")
    generator.save_rules_to_database(generated_rules, generated_dir)
    
    # 3. åˆå§‹åŒ–æ•°æ®åº“å¹¶åŠ è½½æ‰€æœ‰è§„åˆ™
    print("\nğŸ—„ï¸ åˆå§‹åŒ–è§„åˆ™æ•°æ®åº“...")
    database = get_rule_database()
    await database.initialize()
    
    # æ·»åŠ æ–°ç”Ÿæˆçš„è§„åˆ™åˆ°æ•°æ®åº“
    for rule in generated_rules:
        try:
            await database.add_rule(rule)
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ è§„åˆ™å¤±è´¥ {rule.rule_id}: {e}")
    
    # 4. ç”Ÿæˆæ•°æ®åº“ç»Ÿè®¡æŠ¥å‘Š
    stats = database.get_database_stats()
    
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡æŠ¥å‘Š:")
    print(f"  æ€»è§„åˆ™æ•°: {stats['total_rules']}")
    print(f"  æ€»ç‰ˆæœ¬æ•°: {stats['total_versions']}")
    print(f"  æ´»è·ƒè§„åˆ™: {stats['active_rules']}")
    print(f"  æ”¯æŒè¯­è¨€: {stats['languages']} ç§")
    print(f"  è¦†ç›–é¢†åŸŸ: {stats['domains']} ä¸ª")
    print(f"  è§„åˆ™ç±»å‹: {stats['rule_types']} ç§")
    print(f"  æ ‡ç­¾æ€»æ•°: {stats['total_tags']} ä¸ª")
    
    # 5. ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    report_file = Path("data/rules/database_report.json")
    report_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            "migration_date": datetime.now(timezone.utc).isoformat(),
            "migrated_rules": len(migrated_rules),
            "generated_rules": len(generated_rules),
            "database_stats": stats
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ•°æ®åº“è¿ç§»å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
    
    return database


if __name__ == "__main__":
    # æ‰§è¡Œè¿ç§»
    asyncio.run(perform_database_migration())