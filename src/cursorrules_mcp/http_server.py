#!/usr/bin/env python3
"""
CursorRules-MCP HTTPæœåŠ¡å™¨å®ç°
æ”¯æŒMCP JSON-RPCåè®®é€šè¿‡HTTP/SSEä¼ è¾“

Author: Mapoet
Institution: NUS/STAR
Date: 2025-01-23
License: MIT
"""

import asyncio
import json
import logging
from typing import Dict, Any, Optional, AsyncGenerator
from pathlib import Path
import uuid
from datetime import datetime

# HTTPç›¸å…³å¯¼å…¥
try:
    from fastapi import FastAPI, Request, Response
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import StreamingResponse
    import uvicorn
except ImportError:
    print("FastAPIæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install fastapi uvicorn")
    exit(1)

from .engine import RuleEngine
from .models import (
    MCPContext, SearchFilter, ValidationSeverity, RuleType,
    ContentType, TaskType
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MCPHttpServer:
    """
    MCP HTTPæœåŠ¡å™¨
    
    æ”¯æŒé€šè¿‡HTTP/SSEæä¾›MCPæœåŠ¡
    """
    
    def __init__(self, rules_dir: str = "data/rules", host: str = "localhost", port: int = 8000, workers: int = 1):
        """åˆå§‹åŒ–HTTPæœåŠ¡å™¨
        
        Args:
            rules_dir: è§„åˆ™ç›®å½•è·¯å¾„
            host: æœåŠ¡å™¨ä¸»æœºåœ°å€
            port: æœåŠ¡å™¨ç«¯å£
            workers: å·¥ä½œè¿›ç¨‹æ•°é‡ï¼Œé»˜è®¤ä¸º1
        """
        self.app = FastAPI(
            title="CursorRules-MCP HTTP Server",
            description="MCPæœåŠ¡å™¨ - æ”¯æŒHTTP/SSEä¼ è¾“",
            version="1.0.0"
        )
        self.rule_engine = RuleEngine(rules_dir)
        self.host = host
        self.port = port
        self.workers = workers
        self._initialized = False
        self._active_connections: Dict[str, Dict] = {}
        
        self._setup_middleware()
        self._setup_routes()
    
    def _setup_middleware(self):
        """è®¾ç½®ä¸­é—´ä»¶"""
        # CORSä¸­é—´ä»¶
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def _setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        
        @self.app.get("/health")
        async def health_check():
            """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
            return {
                "status": "healthy",
                "service": "cursorrules-mcp",
                "version": "1.0.0",
                "timestamp": datetime.now().isoformat()
            }
        
        @self.app.get("/mcp/info")
        async def mcp_info():
            """MCPæœåŠ¡ä¿¡æ¯"""
            await self._ensure_initialized()
            stats = await self.rule_engine.get_statistics()
            return {
                "protocol": "mcp",
                "version": "2024-11-05",
                "transport": "http-sse",
                "capabilities": {
                    "tools": True,
                    "resources": True,
                    "prompts": False,
                    "logging": True
                },
                "server_info": {
                    "name": "cursorrules-mcp",
                    "version": "1.0.0"
                },
                "statistics": stats
            }
        
        @self.app.post("/mcp/connect")
        async def connect():
            """å»ºç«‹MCPè¿æ¥"""
            connection_id = str(uuid.uuid4())
            self._active_connections[connection_id] = {
                "created_at": datetime.now(),
                "last_activity": datetime.now()
            }
            
            return {
                "connection_id": connection_id,
                "protocol": "mcp",
                "version": "2024-11-05",
                "server_info": {
                    "name": "cursorrules-mcp",
                    "version": "1.0.0"
                },
                "capabilities": {
                    "tools": True,
                    "resources": True
                }
            }
        
        @self.app.post("/mcp/jsonrpc")
        async def handle_jsonrpc(request: Request):
            """å¤„ç†MCP JSON-RPCè¯·æ±‚"""
            try:
                # ç¡®ä¿åˆå§‹åŒ–
                await self._ensure_initialized()
                
                # è§£æJSON-RPCè¯·æ±‚
                body = await request.json()
                
                # éªŒè¯JSON-RPCæ ¼å¼
                if not self._validate_jsonrpc(body):
                    return self._error_response(-32600, "Invalid Request")
                
                # å¤„ç†è¯·æ±‚
                response = await self._handle_mcp_request(body)
                return response
                
            except json.JSONDecodeError:
                return self._error_response(-32700, "Parse error")
            except Exception as e:
                logger.error(f"å¤„ç†JSON-RPCè¯·æ±‚æ—¶å‡ºé”™: {e}")
                return self._error_response(-32603, f"Internal error: {str(e)}")
        
        @self.app.get("/mcp/sse")
        async def sse_endpoint(request: Request, connection_id: Optional[str] = None):
            """SSEç«¯ç‚¹ï¼Œç”¨äºå®æ—¶é€šä¿¡"""
            
            async def event_stream():
                """ç”ŸæˆSSEäº‹ä»¶æµ"""
                try:
                    # å‘é€åˆå§‹è¿æ¥äº‹ä»¶
                    yield self._create_sse_event("connection", {
                        "status": "connected",
                        "connection_id": connection_id or "anonymous",
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    # ä¿æŒè¿æ¥æ´»è·ƒ
                    while True:
                        # å‘é€å¿ƒè·³
                        yield self._create_sse_event("heartbeat", {
                            "timestamp": datetime.now().isoformat()
                        })
                        await asyncio.sleep(30)  # 30ç§’å¿ƒè·³
                        
                except asyncio.CancelledError:
                    logger.info("SSEè¿æ¥å·²æ–­å¼€")
                except Exception as e:
                    logger.error(f"SSEæµé”™è¯¯: {e}")
                    yield self._create_sse_event("error", {
                        "message": str(e),
                        "timestamp": datetime.now().isoformat()
                    })
            
            return StreamingResponse(
                event_stream(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Headers": "*",
                }
            )
    
    def _validate_jsonrpc(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯JSON-RPCè¯·æ±‚æ ¼å¼"""
        required_fields = ["jsonrpc", "method", "id"]
        return all(field in data for field in required_fields) and data["jsonrpc"] == "2.0"
    
    async def _handle_mcp_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†MCPè¯·æ±‚"""
        method = request.get("method")
        params = request.get("params", {})
        request_id = request.get("id")
        
        try:
            # è·¯ç”±åˆ°å¯¹åº”çš„å¤„ç†æ–¹æ³•
            if method == "tools/list":
                result = await self._list_tools()
            elif method == "tools/call":
                result = await self._call_tool(params)
            elif method == "resources/list":
                result = await self._list_resources()
            elif method == "resources/read":
                result = await self._read_resource(params)
            elif method == "initialize":
                result = await self._initialize(params)
            else:
                return self._error_response(-32601, f"Method not found: {method}", request_id)
            
            return {
                "jsonrpc": "2.0",
                "id": request_id,
                "result": result
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†MCPæ–¹æ³• {method} æ—¶å‡ºé”™: {e}")
            return self._error_response(-32603, f"Internal error: {str(e)}", request_id)
    
    async def _initialize(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åˆå§‹åŒ–è¯·æ±‚"""
        await self._ensure_initialized()
        
        return {
            "protocolVersion": "2024-11-05",
            "capabilities": {
                "tools": {},
                "resources": {},
                "logging": {}
            },
            "serverInfo": {
                "name": "cursorrules-mcp",
                "version": "1.0.0"
            }
        }
    
    async def _list_tools(self) -> Dict[str, Any]:
        """åˆ—å‡ºå¯ç”¨å·¥å…·"""
        tools = [
            {
                "name": "search_rules",
                "description": "æœç´¢é€‚ç”¨çš„è§„åˆ™",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"},
                        "languages": {"type": "string", "description": "ç¼–ç¨‹è¯­è¨€åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "domains": {"type": "string", "description": "åº”ç”¨é¢†åŸŸåˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "tags": {"type": "string", "description": "æ ‡ç­¾åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "content_types": {"type": "string", "description": "å†…å®¹ç±»å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "rule_types": {"type": "string", "description": "è§„åˆ™ç±»å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "limit": {"type": "integer", "description": "è¿”å›ç»“æœæ•°é‡é™åˆ¶", "default": 10}
                    }
                }
            },
            {
                "name": "validate_content",
                "description": "éªŒè¯å†…å®¹æ˜¯å¦ç¬¦åˆè§„åˆ™",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "string", "description": "è¦éªŒè¯çš„å†…å®¹"},
                        "file_path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰"},
                        "languages": {"type": "string", "description": "ç¼–ç¨‹è¯­è¨€ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "domains": {"type": "string", "description": "åº”ç”¨é¢†åŸŸï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "content_types": {"type": "string", "description": "å†…å®¹ç±»å‹ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "project_context": {"type": "string", "description": "é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"}
                    },
                    "required": ["content"]
                }
            },
            {
                "name": "enhance_prompt",
                "description": "åŸºäºè§„åˆ™å¢å¼ºæç¤º",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "base_prompt": {"type": "string", "description": "åŸºç¡€æç¤º"},
                        "languages": {"type": "string", "description": "ç¼–ç¨‹è¯­è¨€åˆ—è¡¨"},
                        "domains": {"type": "string", "description": "åº”ç”¨é¢†åŸŸåˆ—è¡¨"},
                        "tags": {"type": "string", "description": "æ ‡ç­¾åˆ—è¡¨"},
                        "max_rules": {"type": "integer", "description": "æœ€å¤§è§„åˆ™æ•°é‡", "default": 5}
                    },
                    "required": ["base_prompt"]
                }
            },
            {
                "name": "get_statistics",
                "description": "è·å–è§„åˆ™åº“ç»Ÿè®¡ä¿¡æ¯",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "languages": {"type": "string", "description": "è¿‡æ»¤çš„ç¼–ç¨‹è¯­è¨€ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "domains": {"type": "string", "description": "è¿‡æ»¤çš„åº”ç”¨é¢†åŸŸï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "rule_types": {"type": "string", "description": "è¿‡æ»¤çš„è§„åˆ™ç±»å‹ï¼ˆé€—å·åˆ†éš”ï¼‰"},
                        "tags": {"type": "string", "description": "è¿‡æ»¤çš„æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰"}
                    }
                }
            },
            {
                "name": "import_rules",
                "description": "å¯¼å…¥è§„åˆ™ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "string", "description": "è§„åˆ™å†…å®¹ï¼ˆå¦‚æœæä¾›äº†contentï¼Œåˆ™å¿½ç•¥file_pathï¼‰"},
                        "file_path": {"type": "string", "description": "è§„åˆ™æ–‡ä»¶è·¯å¾„"},
                        "format": {"type": "string", "description": "æ ¼å¼ç±»å‹", "enum": ["auto", "markdown", "yaml", "json"], "default": "auto"},
                        "validate": {"type": "boolean", "description": "æ˜¯å¦éªŒè¯è§„åˆ™", "default": True},
                        "merge": {"type": "boolean", "description": "æ˜¯å¦åˆå¹¶é‡å¤è§„åˆ™", "default": False}
                    }
                }
            }
        ]
        
        return {"tools": tools}
    
    async def _call_tool(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒç”¨å·¥å…·"""
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        if tool_name == "search_rules":
            result = await self._search_rules(**arguments)
        elif tool_name == "validate_content":
            result = await self._validate_content(**arguments)
        elif tool_name == "enhance_prompt":
            result = await self._enhance_prompt(**arguments)
        elif tool_name == "get_statistics":
            result = await self._get_statistics(**arguments)
        elif tool_name == "import_rules":
            result = await self._import_rules(**arguments)
        else:
            raise ValueError(f"Unknown tool: {tool_name}")
        
        return {
            "content": [
                {
                    "type": "text",
                    "text": result
                }
            ]
        }
    
    async def _list_resources(self) -> Dict[str, Any]:
        """åˆ—å‡ºå¯ç”¨èµ„æº"""
        resources = [
            {
                "uri": "cursorrules://rules/list",
                "name": "è§„åˆ™åˆ—è¡¨",
                "description": "åˆ—å‡ºæ‰€æœ‰å¯ç”¨è§„åˆ™çš„æ‘˜è¦",
                "mimeType": "text/plain"
            }
        ]
        
        return {"resources": resources}
    
    async def _read_resource(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è¯»å–èµ„æº"""
        uri = params.get("uri")
        
        if uri == "cursorrules://rules/list":
            content = await self._list_all_rules()
        elif uri and uri.startswith("cursorrules://rules/"):
            # æå–è§„åˆ™ID
            rule_id = uri.split("/")[-1]
            content = await self._get_rule_detail(rule_id)
        else:
            raise ValueError(f"Unknown resource: {uri}")
        
        return {
            "contents": [
                {
                    "uri": uri,
                    "mimeType": "text/plain",
                    "text": content
                }
            ]
        }
    
    # å·¥å…·å®ç°æ–¹æ³•ï¼ˆé‡ç”¨ç°æœ‰é€»è¾‘ï¼‰
    async def _search_rules(self, query: str = "", languages: str = "", domains: str = "", 
                          tags: str = "", content_types: str = "", rule_types: str = "", limit: int = 10) -> str:
        """æœç´¢è§„åˆ™çš„å®ç°"""
        try:
            # è§£æå‚æ•°
            search_filter = SearchFilter(
                query=query.strip() if query else None,
                languages=self._parse_list_param(languages),
                domains=self._parse_list_param(domains),
                tags=self._parse_list_param(tags),
                content_types=self._parse_list_param(content_types),
                rule_types=[RuleType(rt.strip()) for rt in rule_types.split(',') if rt.strip()] if rule_types else None,
                limit=max(1, min(50, limit))
            )
            
            # æ‰§è¡Œæœç´¢
            applicable_rules = await self.rule_engine.search_rules(search_filter)
            
            if not applicable_rules:
                return "âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è§„åˆ™ã€‚è¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶ã€‚"
            
            # æ ¼å¼åŒ–ç»“æœ
            result_text = f"""ğŸ” **æœç´¢æ‘˜è¦**: 
- æŸ¥è¯¢: "{query}" (å¦‚æœæœ‰)
- æ‰¾åˆ° {len(applicable_rules)} æ¡åŒ¹é…è§„åˆ™

---
"""
            
            for i, applicable_rule in enumerate(applicable_rules, 1):
                rule = applicable_rule.rule
                result_text += f"""
## {i}. {rule.name}
**ID**: `{rule.rule_id}` | **ç‰ˆæœ¬**: {rule.version} | **ç›¸å…³åº¦**: {applicable_rule.relevance_score:.2f}

**æè¿°**: {rule.description}

**åˆ†ç±»ä¿¡æ¯**:
- ğŸ·ï¸ **ç±»å‹**: {rule.rule_type.value}
- ğŸ’» **è¯­è¨€**: {', '.join(rule.languages) if rule.languages else 'é€šç”¨'}
- ğŸŒ **é¢†åŸŸ**: {', '.join(rule.domains) if rule.domains else 'é€šç”¨'}
- ğŸª **æ ‡ç­¾**: {', '.join(rule.tags)}

---
"""
            
            return result_text
            
        except Exception as e:
            logger.error(f"æœç´¢è§„åˆ™æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ æœç´¢å¤±è´¥: {str(e)}"
    
    async def _validate_content(self, content: str, file_path: str = "", 
                              languages: str = "", domains: str = "", 
                              content_types: str = "", project_context: str = "") -> str:
        """éªŒè¯å†…å®¹çš„å®ç°"""
        try:
            # æ„å»ºMCPä¸Šä¸‹æ–‡
            context = MCPContext(
                user_query="Content validation request",
                file_path=file_path,
                languages=self._parse_list_param(languages) or self._infer_languages_from_path(file_path),
                domains=self._parse_list_param(domains),
                content_types=self._parse_list_param(content_types) or self._infer_content_types(content, file_path),
                project_context=project_context
            )
            
            # æ‰§è¡ŒéªŒè¯
            validation_result = await self.rule_engine.validate_content(content, context)
            
            # æ ¼å¼åŒ–éªŒè¯ç»“æœ
            if validation_result.is_valid:
                result_text = f"âœ… **éªŒè¯é€šè¿‡**\n\n"
            else:
                result_text = f"âŒ **éªŒè¯å¤±è´¥** ({len(validation_result.violations)} ä¸ªé—®é¢˜)\n\n"
            
            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            if validation_result.violations:
                result_text += "**å‘ç°çš„é—®é¢˜**:\n"
                for violation in validation_result.violations:
                    result_text += f"- {violation.severity.value}: {violation.message}\n"
                    if violation.suggestion:
                        result_text += f"  ğŸ’¡ å»ºè®®: {violation.suggestion}\n"
            
            if validation_result.suggestions:
                result_text += "\n**æ”¹è¿›å»ºè®®**:\n"
                for suggestion in validation_result.suggestions:
                    result_text += f"- {suggestion}\n"
            
            return result_text
            
        except Exception as e:
            logger.error(f"éªŒè¯å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ éªŒè¯å¤±è´¥: {str(e)}"
    
    async def _enhance_prompt(self, base_prompt: str, languages: str = "", 
                            domains: str = "", tags: str = "", max_rules: int = 5) -> str:
        """å¢å¼ºæç¤ºçš„å®ç°"""
        try:
            # æ„å»ºæœç´¢è¿‡æ»¤å™¨
            search_filter = SearchFilter(
                languages=self._parse_list_param(languages),
                domains=self._parse_list_param(domains),
                tags=self._parse_list_param(tags),
                limit=max_rules
            )
            
            # è·å–ç›¸å…³è§„åˆ™
            applicable_rules = await self.rule_engine.search_rules(search_filter)
            
            enhanced_prompt = f"{base_prompt}\n\n"
            
            if applicable_rules:
                enhanced_prompt += "**ç›¸å…³ç¼–ç¨‹è§„åˆ™**:\n"
                for rule in applicable_rules[:max_rules]:
                    enhanced_prompt += f"- {rule.rule.name}: {rule.rule.description}\n"
            
            return enhanced_prompt
            
        except Exception as e:
            logger.error(f"å¢å¼ºæç¤ºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ å¢å¼ºå¤±è´¥: {str(e)}"
    
    async def _get_statistics(self, languages: str = "", domains: str = "", 
                           rule_types: str = "", tags: str = "") -> str:
        """è·å–ç»Ÿè®¡ä¿¡æ¯çš„å®ç°ï¼ˆæ”¯æŒè¿‡æ»¤å‚æ•°ï¼‰"""
        try:
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            filter_conditions = {}
            if languages:
                filter_conditions['languages'] = self._parse_list_param(languages)
            if domains:
                filter_conditions['domains'] = self._parse_list_param(domains)
            if rule_types:
                filter_conditions['rule_types'] = [RuleType(rt.strip()) for rt in rule_types.split(',') if rt.strip()]
            if tags:
                filter_conditions['tags'] = self._parse_list_param(tags)
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.rule_engine.database.get_database_stats(**filter_conditions)
            
            # æ„å»ºæ ‡é¢˜
            if filter_conditions:
                filter_desc = []
                if filter_conditions.get('languages'):
                    filter_desc.append(f"è¯­è¨€: {', '.join(filter_conditions['languages'])}")
                if filter_conditions.get('domains'):
                    filter_desc.append(f"é¢†åŸŸ: {', '.join(filter_conditions['domains'])}")
                if filter_conditions.get('rule_types'):
                    filter_desc.append(f"ç±»å‹: {', '.join([rt.value for rt in filter_conditions['rule_types']])}")
                if filter_conditions.get('tags'):
                    filter_desc.append(f"æ ‡ç­¾: {', '.join(filter_conditions['tags'])}")
                
                title = f"ğŸ“Š **CursorRules-MCP è§„åˆ™åº“ç»Ÿè®¡ (è¿‡æ»¤æ¡ä»¶: {'; '.join(filter_desc)})**"
            else:
                title = "ğŸ“Š **CursorRules-MCP è§„åˆ™åº“ç»Ÿè®¡**"
            
            result_text = f"""
{title}

**è§„åˆ™ç»Ÿè®¡**:
- æ€»è§„åˆ™æ•°: {stats['total_rules']}
- æ´»è·ƒè§„åˆ™æ•°: {stats['active_rules']}
- ç‰ˆæœ¬æ€»æ•°: {stats['total_versions']}

**åˆ†ç±»ç»Ÿè®¡**:
- æ”¯æŒè¯­è¨€: {stats['languages']} ç§
- åº”ç”¨é¢†åŸŸ: {stats['domains']} ä¸ª
- è§„åˆ™ç±»å‹: {stats['rule_types']} ç§
- æ ‡ç­¾æ€»æ•°: {stats['total_tags']} ä¸ª

**æŒ‰ç±»å‹åˆ†å¸ƒ**:
"""
            # æ·»åŠ è¯¦ç»†åˆ†å¸ƒä¿¡æ¯
            for rule_type, count in stats.get('rules_by_type', {}).items():
                if count > 0:
                    result_text += f"- {rule_type}: {count} æ¡\n"
            
            result_text += f"""
**æŒ‰è¯­è¨€åˆ†å¸ƒ**:
"""
            for lang, count in stats.get('rules_by_language', {}).items():
                if count > 0:
                    result_text += f"- {lang}: {count} æ¡\n"
            
            result_text += f"""
**æŒ‰é¢†åŸŸåˆ†å¸ƒ**:
"""
            for domain, count in stats.get('rules_by_domain', {}).items():
                if count > 0:
                    result_text += f"- {domain}: {count} æ¡\n"
            
            # æ·»åŠ ç‰ˆæœ¬åˆ†å¸ƒ
            if 'version_distribution' in stats and stats['version_distribution']:
                result_text += f"""
**ç‰ˆæœ¬åˆ†å¸ƒ**:
"""
                for rule_id, version_count in list(stats['version_distribution'].items())[:5]:
                    result_text += f"- {rule_id}: {version_count} ä¸ªç‰ˆæœ¬\n"
                
                if len(stats['version_distribution']) > 5:
                    result_text += f"- ... è¿˜æœ‰ {len(stats['version_distribution']) - 5} ä¸ªè§„åˆ™\n"
            
            # æ·»åŠ ä½¿ç”¨æƒ…å†µç»Ÿè®¡
            if 'usage_stats' in stats:
                result_text += f"""
**ä½¿ç”¨æƒ…å†µ**:
- æ€»ä½¿ç”¨æ¬¡æ•°: {stats['usage_stats'].get('total_usage', 0)}
- å¹³å‡æˆåŠŸç‡: {stats['usage_stats'].get('average_success_rate', 0):.1%}
- æœ€å¸¸ç”¨è§„åˆ™: {stats['usage_stats'].get('most_used_rule', 'æ— ')}
"""
            
            result_text += f"""
**HTTPæœåŠ¡çŠ¶æ€**:
- æ´»è·ƒè¿æ¥: {len(self._active_connections)}
- æœåŠ¡å™¨è¿è¡Œæ—¶é—´: {datetime.now().isoformat()}
"""
            
            return result_text
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"

    async def _import_rules(self, content: str = "", file_path: str = "",
                           format: str = "auto", validate: bool = True,
                           merge: bool = False) -> str:
        """å¯¼å…¥è§„åˆ™çš„å®ç°"""
        try:
            # å¯¼å…¥è§„åˆ™å¯¼å…¥å™¨
            from .rule_import import UnifiedRuleImporter
            
            # åˆ›å»ºå¯¼å…¥å™¨
            importer = UnifiedRuleImporter(
                output_dir="data/rules/imported",
                validate=validate,
                merge=merge
            )
            
            # æ‰§è¡Œå¯¼å…¥
            if content:
                # ç›´æ¥ä»å†…å®¹å¯¼å…¥
                if format == "auto":
                    # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                    if content.startswith('---'):
                        format = "markdown"
                    elif content.strip().startswith('{'):
                        format = "json"
                    else:
                        format = "yaml"
                
                result = importer.import_from_content(content, format)
            else:
                # ä»æ–‡ä»¶è·¯å¾„å¯¼å…¥
                if not file_path:
                    return "âŒ å¿…é¡»æä¾› content æˆ– file_path ä¹‹ä¸€"
                
                result = importer.import_from_file(file_path, format)
            
            # æ ¼å¼åŒ–ç»“æœ
            if result['success']:
                result_text = f"""
âœ… **è§„åˆ™å¯¼å…¥æˆåŠŸ**

**å¯¼å…¥ç»Ÿè®¡**:
- å¤„ç†æ–‡ä»¶: {result.get('processed_files', 1)}
- å¯¼å…¥è§„åˆ™: {result.get('imported_rules', 0)}
- è·³è¿‡è§„åˆ™: {result.get('skipped_rules', 0)}
- æ ¼å¼: {result.get('detected_format', format)}

"""
                if result.get('imported_rule_ids'):
                    result_text += "**å·²å¯¼å…¥çš„è§„åˆ™ID**:\n"
                    for rule_id in result['imported_rule_ids']:
                        result_text += f"- {rule_id}\n"
                
                if result.get('warnings'):
                    result_text += "\n**è­¦å‘Š**:\n"
                    for warning in result['warnings']:
                        result_text += f"âš ï¸ {warning}\n"
            else:
                result_text = f"""
âŒ **è§„åˆ™å¯¼å…¥å¤±è´¥**

**é”™è¯¯ä¿¡æ¯**: {result.get('error', 'æœªçŸ¥é”™è¯¯')}

"""
                if result.get('details'):
                    result_text += f"**è¯¦ç»†ä¿¡æ¯**: {result['details']}\n"
            
            # é‡æ–°åŠ è½½è§„åˆ™å¼•æ“
            await self.rule_engine.reload()
            
            return result_text
            
        except Exception as e:
            logger.error(f"å¯¼å…¥è§„åˆ™æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}"
    
    async def _list_all_rules(self) -> str:
        """åˆ—å‡ºæ‰€æœ‰è§„åˆ™"""
        try:
            # è·å–æ‰€æœ‰è§„åˆ™
            all_rules = await self.rule_engine.search_rules(SearchFilter(limit=1000))
            
            if not all_rules:
                return "ğŸ“‹ **è§„åˆ™åº“ä¸ºç©º**\n\nå½“å‰æ²¡æœ‰å¯ç”¨çš„è§„åˆ™ã€‚"
            
            result_text = f"ğŸ“‹ **CursorRules è§„åˆ™åº“** ({len(all_rules)} æ¡è§„åˆ™)\n\n"
            
            for i, applicable_rule in enumerate(all_rules, 1):
                rule = applicable_rule.rule
                result_text += f"{i}. **{rule.name}** (`{rule.rule_id}`)\n"
                result_text += f"   {rule.description}\n"
                result_text += f"   ğŸ·ï¸ {rule.rule_type.value} | ğŸ’» {', '.join(rule.languages[:2]) if rule.languages else 'é€šç”¨'}\n\n"
            
            return result_text
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºè§„åˆ™æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ åˆ—å‡ºè§„åˆ™å¤±è´¥: {str(e)}"
    
    async def _get_rule_detail(self, rule_id: str) -> str:
        """è·å–è§„åˆ™è¯¦æƒ…"""
        try:
            rule = await self.rule_engine.get_rule_by_id(rule_id)
            
            if not rule:
                return f"âŒ æœªæ‰¾åˆ°è§„åˆ™: {rule_id}"
            
            # æ ¼å¼åŒ–è§„åˆ™è¯¦æƒ…ï¼ˆè¿™é‡Œå¯ä»¥é‡ç”¨ç°æœ‰é€»è¾‘ï¼‰
            # ... å®ç°è¯¦ç»†æ ¼å¼åŒ–
            
            return f"ğŸ“‹ **è§„åˆ™è¯¦æƒ…**: {rule.name}\n\n{rule.description}"
            
        except Exception as e:
            logger.error(f"è·å–è§„åˆ™è¯¦æƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return f"âŒ è·å–è§„åˆ™è¯¦æƒ…å¤±è´¥: {str(e)}"
    
    # è¾…åŠ©æ–¹æ³•
    def _parse_list_param(self, param: str) -> Optional[list]:
        """è§£æåˆ—è¡¨å‚æ•°"""
        if not param or not param.strip():
            return None
        return [item.strip() for item in param.split(',') if item.strip()]
    
    def _infer_languages_from_path(self, file_path: str) -> list:
        """ä»æ–‡ä»¶è·¯å¾„æ¨æ–­ç¼–ç¨‹è¯­è¨€"""
        if not file_path:
            return []
        
        extension_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.cpp': 'cpp',
            '.hpp': 'cpp',
            '.c': 'c',
            '.h': 'c',
            '.cu': 'cuda',
            '.cuh': 'cuda',
            '.cu++': 'cuda',
            '.cu++h': 'cuda',
            '.cu++h++': 'cuda',
            '.f': 'fortran',
            '.f90': 'fortran',
            '.f95': 'fortran',
            '.f03': 'fortran',
            '.f08': 'fortran',
            '.f18': 'fortran',
            '.f20': 'fortran',
            '.f23': 'fortran',
            '.sh': 'shell',
            '.java': 'java',
            '.go': 'go',
            '.rs': 'rust',
            '.php': 'php',
            '.rb': 'ruby',
            '.sql': 'sql',
            '.md': 'markdown',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.json': 'json',
            '.xml': 'xml',
            '.toml': 'toml',
            '.ini': 'ini',
            '.conf': 'conf',
            '.cfg': 'conf',
            '.config': 'conf',
            '.settings': 'conf',
            '.properties': 'conf',
            '.env': 'conf',
            '.html': 'html',
            '.css': 'css'
        }
        
        ext = Path(file_path).suffix.lower()
        return [extension_map[ext]] if ext in extension_map else []
    
    def _infer_content_types(self, content: str, file_path: str) -> list:
        """æ¨æ–­å†…å®¹ç±»å‹"""
        content_types = []
        
        # åŸºäºæ–‡ä»¶æ‰©å±•å
        if file_path:
            ext = Path(file_path).suffix.lower()
            if ext in ['.py', '.js', '.cpp','.hpp','.h','.c', '.java', '.go', '.rs', '.cu', '.cuh', '.cu++', '.cu++h', '.cu++h++']:
                content_types.append('code')
            elif ext in ['.md', '.txt', '.rst']:
                content_types.append('documentation')
            elif ext in ['.yaml', '.yml', '.json', '.xml', '.toml', '.ini', '.conf', '.cfg', '.config', '.settings', '.properties', '.env']:
                content_types.append('configuration')
        
        # åŸºäºå†…å®¹ç‰¹å¾
        if 'def ' in content or 'function ' in content or 'class ' in content:
            content_types.append('code')
        if '# ' in content or '## ' in content or '### ' in content:
            content_types.append('documentation')
        
        return content_types or ['code']  # é»˜è®¤ä¸ºä»£ç 
    
    def _create_sse_event(self, event_type: str, data: Dict[str, Any]) -> str:
        """åˆ›å»ºSSEäº‹ä»¶"""
        return f"event: {event_type}\ndata: {json.dumps(data)}\n\n"
    
    def _error_response(self, code: int, message: str, request_id: Any = None) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": code,
                "message": message
            },
            "id": request_id
        }
    
    async def _ensure_initialized(self):
        """ç¡®ä¿æœåŠ¡å™¨å·²åˆå§‹åŒ–"""
        if not self._initialized:
            logger.info("æ­£åœ¨åˆå§‹åŒ–è§„åˆ™å¼•æ“...")
            await self.rule_engine.initialize()
            self._initialized = True
            logger.info("âœ… è§„åˆ™å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def run(self):
        """è¿è¡ŒHTTPæœåŠ¡å™¨"""
        logger.info(f"ğŸš€ å¯åŠ¨CursorRules-MCP HTTPæœåŠ¡å™¨: http://{self.host}:{self.port}")
        if self.workers > 1:
            logger.info(f"ğŸ‘¥ ä½¿ç”¨ {self.workers} ä¸ªå·¥ä½œè¿›ç¨‹")
            # å¤šè¿›ç¨‹æ¨¡å¼éœ€è¦ä½¿ç”¨å¯¼å…¥å­—ç¬¦ä¸²
            uvicorn.run(
                "src.cursorrules_mcp.http_server:create_app",
                host=self.host,
                port=self.port,
                log_level="info",
                workers=self.workers,
                factory=True
            )
        else:
            # å•è¿›ç¨‹æ¨¡å¼å¯ä»¥ç›´æ¥ä¼ é€’appå¯¹è±¡
            uvicorn.run(
                self.app,
                host=self.host,
                port=self.port,
                log_level="info"
            )


def create_app():
    """
    åº”ç”¨ç¨‹åºå·¥å‚å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹æ¨¡å¼
    ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    
    Returns:
        FastAPIåº”ç”¨å®ä¾‹
    """
    import os
    
    rules_dir = os.getenv("CURSORRULES_RULES_DIR", "data/rules")
    host = os.getenv("CURSORRULES_HOST", "localhost")
    port = int(os.getenv("CURSORRULES_PORT", "8000"))
    workers = int(os.getenv("CURSORRULES_WORKERS", "1"))
    
    server = MCPHttpServer(rules_dir=rules_dir, host=host, port=port, workers=workers)
    return server.app
