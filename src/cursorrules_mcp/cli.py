#!/usr/bin/env python3
"""
CursorRules-MCP å‘½ä»¤è¡Œæ¥å£
æä¾›è§„åˆ™ç®¡ç†ã€éªŒè¯å’ŒæœåŠ¡å™¨æ§åˆ¶çš„å‘½ä»¤è¡Œå·¥å…·

Author: Mapoet
Institution: NUS/STAR
Date: 2025-01-23
License: MIT
"""

import asyncio
import sys
import json
import argparse
import logging
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime

from .config import get_config_manager, create_default_config, ConfigManager
from .engine import RuleEngine
from .server import CursorRulesMCPServer
from .validators import get_validation_manager
from .models import SearchFilter, MCPContext

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CLI:
    """å‘½ä»¤è¡Œæ¥å£ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–CLI"""
        self.config_manager = get_config_manager()
        self.config = self.config_manager.config
        
    async def run(self, args: List[str]) -> int:
        """è¿è¡ŒCLIå‘½ä»¤
        
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            
        Returns:
            é€€å‡ºä»£ç 
        """
        parser = self._create_parser()
        parsed_args = parser.parse_args(args)
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if hasattr(parsed_args, 'verbose') and parsed_args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        elif hasattr(parsed_args, 'quiet') and parsed_args.quiet:
            logging.getLogger().setLevel(logging.WARNING)
        
        try:
            # æ‰§è¡Œå¯¹åº”çš„å‘½ä»¤
            if parsed_args.command == 'server':
                return await self._run_server(parsed_args)
            elif parsed_args.command == 'search':
                return await self._search_rules(parsed_args)
            elif parsed_args.command == 'validate':
                return await self._validate_content(parsed_args)
            elif parsed_args.command == 'config':
                return await self._manage_config(parsed_args)
            elif parsed_args.command == 'stats':
                return await self._show_stats(parsed_args)
            elif parsed_args.command == 'test':
                return await self._test_tools(parsed_args)
            elif parsed_args.command == 'import':
                return await self._import_rules(parsed_args)
            else:
                parser.print_help()
                return 1
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
            return 1
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‘½ä»¤å¤±è´¥: {e}")
            if hasattr(parsed_args, 'verbose') and parsed_args.verbose:
                import traceback
                traceback.print_exc()
            return 1
    
    def _create_parser(self) -> argparse.ArgumentParser:
        """åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨"""
        parser = argparse.ArgumentParser(
            prog='cursorrules-mcp',
            description='CursorRules-MCP å‘½ä»¤è¡Œå·¥å…·',
            epilog="""
ç¤ºä¾‹:
  cursorrules-mcp server                    # å¯åŠ¨MCPæœåŠ¡å™¨
  cursorrules-mcp search --language python # æœç´¢Pythonè§„åˆ™
  cursorrules-mcp validate file.py         # éªŒè¯Pythonæ–‡ä»¶
  cursorrules-mcp config init               # åˆå§‹åŒ–é…ç½®æ–‡ä»¶
  cursorrules-mcp stats                     # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            """,
            formatter_class=argparse.RawDescriptionHelpFormatter
        )
        
        # å…¨å±€é€‰é¡¹
        parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
        parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
        parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼')
        parser.add_argument('--version', action='version', version='cursorrules-mcp 1.0.0')
        
        # å­å‘½ä»¤
        subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
        
        # æœåŠ¡å™¨å‘½ä»¤
        server_parser = subparsers.add_parser('server', help='å¯åŠ¨MCPæœåŠ¡å™¨')
        server_parser.add_argument('--host', default='localhost', help='æœåŠ¡å™¨ä¸»æœºåœ°å€')
        server_parser.add_argument('--port', type=int, default=8000, help='æœåŠ¡å™¨ç«¯å£')
        server_parser.add_argument('--reload', action='store_true', help='å¯ç”¨è‡ªåŠ¨é‡è½½')
        
        # æœç´¢å‘½ä»¤
        search_parser = subparsers.add_parser('search', help='æœç´¢è§„åˆ™')
        search_parser.add_argument('query', nargs='?', default='', help='æœç´¢å…³é”®è¯')
        search_parser.add_argument('--language', '-l', action='append', help='ç¼–ç¨‹è¯­è¨€')
        search_parser.add_argument('--domain', '-d', action='append', help='åº”ç”¨é¢†åŸŸ')
        search_parser.add_argument('--tag', '-t', action='append', help='æ ‡ç­¾')
        search_parser.add_argument('--limit', type=int, default=10, help='ç»“æœæ•°é‡é™åˆ¶')
        search_parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
        
        # éªŒè¯å‘½ä»¤
        validate_parser = subparsers.add_parser('validate', help='éªŒè¯æ–‡ä»¶å†…å®¹')
        validate_parser.add_argument('files', nargs='+', help='è¦éªŒè¯çš„æ–‡ä»¶')
        validate_parser.add_argument('--language', '-l', help='å¼ºåˆ¶æŒ‡å®šç¼–ç¨‹è¯­è¨€')
        validate_parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
        validate_parser.add_argument('--fix', action='store_true', help='å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜')
        
        # é…ç½®å‘½ä»¤
        config_parser = subparsers.add_parser('config', help='é…ç½®ç®¡ç†')
        config_subparsers = config_parser.add_subparsers(dest='config_action', help='é…ç½®æ“ä½œ')
        
        # é…ç½®å­å‘½ä»¤
        config_subparsers.add_parser('init', help='åˆå§‹åŒ–é»˜è®¤é…ç½®æ–‡ä»¶')
        config_subparsers.add_parser('validate', help='éªŒè¯é…ç½®æ–‡ä»¶')
        config_subparsers.add_parser('show', help='æ˜¾ç¤ºå½“å‰é…ç½®')
        
        config_set_parser = config_subparsers.add_parser('set', help='è®¾ç½®é…ç½®å€¼')
        config_set_parser.add_argument('key', help='é…ç½®é”®')
        config_set_parser.add_argument('value', help='é…ç½®å€¼')
        
        config_get_parser = config_subparsers.add_parser('get', help='è·å–é…ç½®å€¼')
        config_get_parser.add_argument('key', help='é…ç½®é”®')
        
        # ç»Ÿè®¡å‘½ä»¤
        stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
        stats_parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
        
        # æµ‹è¯•å‘½ä»¤
        test_parser = subparsers.add_parser('test', help='æµ‹è¯•éªŒè¯å·¥å…·')
        test_parser.add_argument('--language', '-l', help='æµ‹è¯•ç‰¹å®šè¯­è¨€çš„å·¥å…·')
        test_parser.add_argument('--tool', '-t', help='æµ‹è¯•ç‰¹å®šå·¥å…·')
        
        # å¯¼å…¥å‘½ä»¤
        import_parser = subparsers.add_parser('import', help='å¯¼å…¥å¤šæ ¼å¼è§„åˆ™æ–‡ä»¶')
        import_parser.add_argument('paths', nargs='+', help='è¦å¯¼å…¥çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
        import_parser.add_argument('--format', choices=['auto', 'markdown', 'yaml', 'json'], 
                                 default='auto', help='æŒ‡å®šæ–‡ä»¶æ ¼å¼')
        import_parser.add_argument('--recursive', '-r', action='store_true', help='é€’å½’æ‰«æç›®å½•')
        import_parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•')
        import_parser.add_argument('--validate', action='store_true', help='å¯¼å…¥åéªŒè¯è§„åˆ™')
        import_parser.add_argument('--merge', action='store_true', help='ä¸ç°æœ‰è§„åˆ™åˆå¹¶')
        import_parser.add_argument('--log', help='ä¿å­˜å¯¼å…¥æ—¥å¿—çš„æ–‡ä»¶è·¯å¾„')
        
        return parser
    
        async def _migrate_database(self, args) -> None:
            """æ‰§è¡Œæ•°æ®åº“è¿ç§»"""
            from .migration import perform_database_migration
            
            print("ğŸš€ å¼€å§‹æ‰§è¡Œè§„åˆ™åº“æ•°æ®åŒ–è¿ç§»...")
            
            try:
                database = await perform_database_migration()
                
                print("âœ… è¿ç§»å®Œæˆï¼")
                stats = database.get_database_stats()
                
                print(f"\nğŸ“Š è¿ç§»ç»“æœ:")
                print(f"  æ€»è§„åˆ™æ•°: {stats['total_rules']}")
                print(f"  ç‰ˆæœ¬æ•°: {stats['total_versions']}")
                print(f"  æ´»è·ƒè§„åˆ™: {stats['active_rules']}")
                print(f"  æ”¯æŒè¯­è¨€: {stats['languages']} ç§")
                print(f"  è¦†ç›–é¢†åŸŸ: {stats['domains']} ä¸ª")
                
            except Exception as e:
                print(f"âŒ è¿ç§»å¤±è´¥: {e}")
                import traceback
                if args.verbose:
                    traceback.print_exc()    
    async def _run_server(self, args) -> int:
        """è¿è¡ŒMCPæœåŠ¡å™¨"""
        try:
            print("ğŸš€ å¯åŠ¨ CursorRules-MCP æœåŠ¡å™¨...")
            
            # æ›´æ–°é…ç½®
            if args.host != 'localhost':
                self.config.server.host = args.host
            if args.port != 8000:
                self.config.server.port = args.port
            if args.reload:
                self.config.server.reload = True
            
            # åˆ›å»ºå¹¶å¯åŠ¨æœåŠ¡å™¨
            server = CursorRulesMCPServer(self.config.rules_dir)
            await server.run()
            
            return 0
            
        except Exception as e:
            logger.error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
            return 1
    
    async def _search_rules(self, args) -> int:
        """æœç´¢è§„åˆ™"""
        try:
            # åˆå§‹åŒ–è§„åˆ™å¼•æ“
            engine = RuleEngine(self.config.rules_dir)
            await engine.initialize()
            
            if len(engine.rules) == 0:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§„åˆ™ï¼Œè¯·æ£€æŸ¥è§„åˆ™ç›®å½•é…ç½®")
                return 1
            
            # æ„å»ºæœç´¢è¿‡æ»¤å™¨
            search_filter = SearchFilter(
                query=args.query if args.query else None,
                languages=args.language or [],
                domains=args.domain or [],
                tags=args.tag or [],
                limit=args.limit
            )
            
            # æ‰§è¡Œæœç´¢
            results = await engine.search_rules(search_filter)
            
            if args.format == 'json':
                # JSONè¾“å‡º
                output = []
                for applicable_rule in results:
                    rule = applicable_rule.rule
                    output.append({
                        'rule_id': rule.rule_id,
                        'name': rule.name,
                        'description': rule.description,
                        'relevance_score': applicable_rule.relevance_score,
                        'languages': rule.languages,
                        'domains': rule.domains,
                        'tags': rule.tags
                    })
                
                print(json.dumps(output, ensure_ascii=False, indent=2))
            else:
                # æ–‡æœ¬è¾“å‡º
                if not results:
                    print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è§„åˆ™")
                    return 1
                
                print(f"ğŸ” æ‰¾åˆ° {len(results)} æ¡åŒ¹é…è§„åˆ™:\n")
                
                for i, applicable_rule in enumerate(results, 1):
                    rule = applicable_rule.rule
                    print(f"{i}. **{rule.name}** (ID: {rule.rule_id})")
                    print(f"   ç›¸å…³åº¦: {applicable_rule.relevance_score:.2f}")
                    print(f"   æè¿°: {rule.description}")
                    print(f"   è¯­è¨€: {', '.join(rule.languages) if rule.languages else 'é€šç”¨'}")
                    print(f"   é¢†åŸŸ: {', '.join(rule.domains) if rule.domains else 'é€šç”¨'}")
                    print(f"   æ ‡ç­¾: {', '.join(rule.tags)}")
                    print()
            
            return 0
            
        except Exception as e:
            logger.error(f"æœç´¢è§„åˆ™å¤±è´¥: {e}")
            return 1
    
    async def _validate_content(self, args) -> int:
        """éªŒè¯æ–‡ä»¶å†…å®¹"""
        try:
            validation_manager = get_validation_manager()
            all_results = []
            total_score = 0.0
            
            for file_path in args.files:
                path = Path(file_path)
                
                if not path.exists():
                    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    continue
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    print(f"âš ï¸ è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶: {file_path}")
                    continue
                
                # æ¨æ–­è¯­è¨€
                language = args.language or self._infer_language(path)
                
                if not language:
                    print(f"âš ï¸ æ— æ³•æ¨æ–­æ–‡ä»¶è¯­è¨€: {file_path}")
                    continue
                
                # æ‰§è¡ŒéªŒè¯
                print(f"ğŸ” éªŒè¯æ–‡ä»¶: {file_path} (è¯­è¨€: {language})")
                
                start_time = datetime.now()
                result = await validation_manager.validate_content(content, language, str(path))
                result.validation_time = datetime.now()
                
                all_results.append({
                    'file': str(path),
                    'language': language,
                    'result': result
                })
                
                total_score += result.score
                
                if args.format == 'text':
                    self._print_validation_result(path, result)
                
                # å°è¯•è‡ªåŠ¨ä¿®å¤
                if args.fix and not result.is_valid:
                    await self._auto_fix_issues(path, language, result.issues)
            
            if args.format == 'json':
                # JSONè¾“å‡º
                output = []
                for item in all_results:
                    result = item['result']
                    output.append({
                        'file': item['file'],
                        'language': item['language'],
                        'is_valid': result.is_valid,
                        'score': result.score,
                        'issues_count': len(result.issues),
                        'issues': [
                            {
                                'line': issue.line_number,
                                'column': issue.column_number,
                                'message': issue.message,
                                'severity': issue.severity.value,
                                'rule_id': issue.rule_id
                            }
                            for issue in result.issues
                        ]
                    })
                
                print(json.dumps(output, ensure_ascii=False, indent=2))
            else:
                # æ˜¾ç¤ºæ€»ç»“
                if len(all_results) > 1:
                    avg_score = total_score / len(all_results)
                    valid_files = sum(1 for item in all_results if item['result'].is_valid)
                    
                    print("\n" + "="*60)
                    print(f"ğŸ“Š éªŒè¯æ€»ç»“:")
                    print(f"   æ€»æ–‡ä»¶æ•°: {len(all_results)}")
                    print(f"   é€šè¿‡éªŒè¯: {valid_files}")
                    print(f"   å¹³å‡åˆ†æ•°: {avg_score:.1f}")
                    print(f"   æ€»ä½“çŠ¶æ€: {'âœ… é€šè¿‡' if valid_files == len(all_results) else 'âŒ å­˜åœ¨é—®é¢˜'}")
            
            # è¿”å›ç ï¼šæ‰€æœ‰æ–‡ä»¶éƒ½é€šè¿‡éªŒè¯è¿”å›0ï¼Œå¦åˆ™è¿”å›1
            return 0 if all(item['result'].is_valid for item in all_results) else 1
            
        except Exception as e:
            logger.error(f"éªŒè¯æ–‡ä»¶å¤±è´¥: {e}")
            return 1
    
    def _print_validation_result(self, file_path: Path, result) -> None:
        """æ‰“å°éªŒè¯ç»“æœ"""
        status = "âœ… é€šè¿‡" if result.is_valid else "âŒ å­˜åœ¨é—®é¢˜"
        print(f"   ç»“æœ: {status} (åˆ†æ•°: {result.score:.1f}/100)")
        
        if result.issues:
            print(f"   å‘ç° {len(result.issues)} ä¸ªé—®é¢˜:")
            
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
            by_severity = {}
            for issue in result.issues:
                severity = issue.severity.value
                if severity not in by_severity:
                    by_severity[severity] = []
                by_severity[severity].append(issue)
            
            # æ˜¾ç¤ºé—®é¢˜
            for severity in ['error', 'warning', 'info']:
                if severity in by_severity:
                    issues = by_severity[severity]
                    icon = {'error': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}[severity]
                    print(f"     {icon} {severity.upper()} ({len(issues)}ä¸ª):")
                    
                    for issue in issues[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                        location = f"{issue.line_number}:{issue.column_number}"
                        print(f"       {location} {issue.message}")
                    
                    if len(issues) > 5:
                        print(f"       ... è¿˜æœ‰ {len(issues) - 5} ä¸ª{severity}é—®é¢˜")
        
        if result.suggestions:
            print(f"   å»ºè®®:")
            for suggestion in result.suggestions[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå»ºè®®
                print(f"     ğŸ’¡ {suggestion}")
        
        print()
    
    async def _auto_fix_issues(self, file_path: Path, language: str, issues) -> None:
        """å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜"""
        if language == 'python':
            # å°è¯•ä½¿ç”¨blackæ ¼å¼åŒ–
            try:
                import subprocess
                result = subprocess.run(
                    ['black', str(file_path)],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    print(f"   ğŸ”§ å·²ä½¿ç”¨blackæ ¼å¼åŒ–: {file_path}")
                else:
                    print(f"   âš ï¸ blackæ ¼å¼åŒ–å¤±è´¥: {result.stderr}")
                    
            except (subprocess.TimeoutExpired, FileNotFoundError):
                print(f"   âš ï¸ blackå·¥å…·ä¸å¯ç”¨")
        
        # å¯ä»¥æ·»åŠ å…¶ä»–è¯­è¨€çš„è‡ªåŠ¨ä¿®å¤é€»è¾‘
    
    def _infer_language(self, file_path: Path) -> Optional[str]:
        """æ¨æ–­æ–‡ä»¶çš„ç¼–ç¨‹è¯­è¨€"""
        ext = file_path.suffix.lower()
        
        language_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.jsx': 'javascript',
            '.ts': 'typescript',
            '.tsx': 'typescript',
            '.cpp': 'cpp',
            '.cc': 'cpp',
            '.cxx': 'cpp',
            '.c++': 'cpp',
            '.c': 'c',
            '.h': 'c',
            '.hpp': 'cpp',
            '.java': 'java',
            '.go': 'go',
            '.rs': 'rust',
            '.sh': 'shell',
            '.bash': 'shell',
            '.md': 'markdown',
            '.markdown': 'markdown',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.json': 'json'
        }
        
        return language_map.get(ext)
    
    async def _manage_config(self, args) -> int:
        """ç®¡ç†é…ç½®"""
        try:
            if args.config_action == 'init':
                # åˆå§‹åŒ–é…ç½®æ–‡ä»¶
                output_file = 'cursorrules.yaml'
                create_default_config(output_file)
                return 0
                
            elif args.config_action == 'validate':
                # éªŒè¯é…ç½®
                errors = self.config_manager.validate()
                if errors:
                    print("âŒ é…ç½®éªŒè¯å¤±è´¥:")
                    for error in errors:
                        print(f"  - {error}")
                    return 1
                else:
                    print("âœ… é…ç½®éªŒè¯é€šè¿‡")
                    return 0
                    
            elif args.config_action == 'show':
                # æ˜¾ç¤ºé…ç½®
                print(json.dumps(self.config_manager.to_dict(), ensure_ascii=False, indent=2))
                return 0
                
            elif args.config_action == 'set':
                # è®¾ç½®é…ç½®å€¼
                try:
                    # å°è¯•å°†å€¼è½¬æ¢ä¸ºåˆé€‚çš„ç±»å‹
                    value = args.value
                    if value.lower() in ['true', 'false']:
                        value = value.lower() == 'true'
                    elif value.isdigit():
                        value = int(value)
                    
                    self.config_manager.set(args.key, value)
                    self.config_manager.save()
                    print(f"âœ… é…ç½®å·²æ›´æ–°: {args.key} = {value}")
                    return 0
                except Exception as e:
                    print(f"âŒ è®¾ç½®é…ç½®å¤±è´¥: {e}")
                    return 1
                    
            elif args.config_action == 'get':
                # è·å–é…ç½®å€¼
                value = self.config_manager.get(args.key)
                if value is not None:
                    print(f"{args.key} = {value}")
                    return 0
                else:
                    print(f"âŒ é…ç½®é”®ä¸å­˜åœ¨: {args.key}")
                    return 1
            else:
                print("âŒ æ— æ•ˆçš„é…ç½®æ“ä½œ")
                return 1
                
        except Exception as e:
            logger.error(f"é…ç½®ç®¡ç†å¤±è´¥: {e}")
            return 1
    
    async def _show_stats(self, args) -> int:
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        try:
            # åˆå§‹åŒ–è§„åˆ™å¼•æ“
            engine = RuleEngine(self.config.rules_dir)
            await engine.initialize()
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = await engine.get_statistics()
            
            if args.format == 'json':
                print(json.dumps(stats, ensure_ascii=False, indent=2))
            else:
                print("ğŸ“Š CursorRules-MCP ç»Ÿè®¡ä¿¡æ¯\n")
                print(f"ğŸ“ æ€»è§„åˆ™æ•°: {stats['total_rules']}")
                print(f"â° æ•°æ®åŠ è½½æ—¶é—´: {stats['loaded_at'] or 'æœªçŸ¥'}")
                print(f"ğŸ“ˆ å¹³å‡æˆåŠŸç‡: {stats['average_success_rate']:.1%}")
                
                print("\nğŸ·ï¸ è§„åˆ™ç±»å‹åˆ†å¸ƒ:")
                for rule_type, count in stats['rules_by_type'].items():
                    if count > 0:
                        percentage = (count / stats['total_rules']) * 100
                        print(f"  {rule_type}: {count} ({percentage:.1f}%)")
                
                print("\nğŸ’» ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ:")
                for language, count in sorted(stats['rules_by_language'].items()):
                    print(f"  {language}: {count} æ¡è§„åˆ™")
                
                print("\nğŸŒ åº”ç”¨é¢†åŸŸåˆ†å¸ƒ:")
                for domain, count in sorted(stats['rules_by_domain'].items()):
                    print(f"  {domain}: {count} æ¡è§„åˆ™")
                
                print(f"\nğŸ” ç´¢å¼•ä¿¡æ¯:")
                print(f"  æ ‡ç­¾æ€»æ•°: {stats['total_tags']}")
                print(f"  è¯­è¨€ç´¢å¼•: {len(stats['rules_by_language'])} ç§è¯­è¨€")
                print(f"  é¢†åŸŸç´¢å¼•: {len(stats['rules_by_domain'])} ä¸ªé¢†åŸŸ")
            
            return 0
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return 1
    
    async def _test_tools(self, args) -> int:
        """æµ‹è¯•éªŒè¯å·¥å…·"""
        try:
            validation_manager = get_validation_manager()
            available_validators = validation_manager.get_available_validators()
            
            if not available_validators:
                print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„éªŒè¯å·¥å…·")
                return 1
            
            print("ğŸ”§ å¯ç”¨çš„éªŒè¯å·¥å…·:\n")
            
            languages_to_test = [args.language] if args.language else available_validators.keys()
            
            for language in languages_to_test:
                if language not in available_validators:
                    print(f"âŒ ä¸æ”¯æŒçš„è¯­è¨€: {language}")
                    continue
                
                tools = available_validators[language]
                if args.tool and args.tool not in tools:
                    print(f"âŒ è¯­è¨€ {language} ä¸æ”¯æŒå·¥å…·: {args.tool}")
                    continue
                
                tools_to_test = [args.tool] if args.tool else tools
                
                print(f"ğŸ’» {language.upper()}:")
                
                for tool in tools_to_test:
                    if validation_manager.is_tool_available(language, tool):
                        # æµ‹è¯•å·¥å…·
                        test_content = self._get_test_content(language)
                        
                        try:
                            result = await validation_manager.validate_content(
                                test_content, language
                            )
                            
                            status = "âœ… æ­£å¸¸" if result.score > 0 else "âš ï¸ æœ‰é—®é¢˜"
                            print(f"  {tool}: {status} (åˆ†æ•°: {result.score:.1f})")
                            
                        except Exception as e:
                            print(f"  {tool}: âŒ é”™è¯¯ ({e})")
                    else:
                        print(f"  {tool}: âŒ ä¸å¯ç”¨")
                
                print()
            
            return 0
            
        except Exception as e:
            logger.error(f"æµ‹è¯•éªŒè¯å·¥å…·å¤±è´¥: {e}")
            return 1
    
    def _get_test_content(self, language: str) -> str:
        """è·å–æµ‹è¯•å†…å®¹"""
        test_contents = {
            'python': '''def test_function():
    x = 1
    return x
''',
            'javascript': '''function testFunction() {
    let x = 1;
    return x;
}
''',
            'markdown': '''# Test Document

This is a test document.

## Section

Content here.
''',
            'cpp': '''#include <iostream>

int main() {
    std::cout << "Hello World" << std::endl;
    return 0;
}
'''
        }
        
        return test_contents.get(language, '// Test content')

    async def _import_rules(self, args) -> int:
        """å¯¼å…¥å¤šæ ¼å¼è§„åˆ™æ–‡ä»¶"""
        try:
            from .rule_import import UnifiedRuleImporter
            from .database import get_rule_database
            
            print("ğŸš€ å¼€å§‹å¯¼å…¥è§„åˆ™æ–‡ä»¶...")
            
            # åˆ›å»ºå¯¼å…¥å™¨
            importer = UnifiedRuleImporter()
            
            # æ‰§è¡Œå¯¼å…¥
            rules = importer.import_rules(
                paths=args.paths,
                recursive=args.recursive,
                format_hint=args.format if args.format != 'auto' else None
            )
            
            if not rules:
                print("âŒ æœªèƒ½å¯¼å…¥ä»»ä½•è§„åˆ™")
                return 1
            
            print(f"âœ… æˆåŠŸè§£æ {len(rules)} æ¡è§„åˆ™")
            
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼Œä¿å­˜åˆ°æ–‡ä»¶
            if args.output_dir:
                output_dir = Path(args.output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
                
                # ä¿å­˜ä¸ºJSONæ ¼å¼
                output_file = output_dir / "imported_rules.json"
                rules_data = [rule.dict() for rule in rules]
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    import json
                    json.dump(rules_data, f, indent=2, ensure_ascii=False, default=str)
                
                print(f"ğŸ’¾ è§„åˆ™å·²ä¿å­˜åˆ°: {output_file}")
            
            # å¦‚æœå¯ç”¨åˆå¹¶ï¼Œæ·»åŠ åˆ°æ•°æ®åº“
            if args.merge:
                print("ğŸ”„ æ­£åœ¨åˆå¹¶åˆ°è§„åˆ™æ•°æ®åº“...")
                
                try:
                    database = get_rule_database()
                    await database.initialize()
                    
                    added_count = 0
                    updated_count = 0
                    
                    for rule in rules:
                        existing_rule = database.get_rule_by_id(rule.rule_id)
                        
                        if existing_rule:
                            # æ›´æ–°ç°æœ‰è§„åˆ™
                            database.update_rule(rule)
                            updated_count += 1
                            print(f"ğŸ”„ æ›´æ–°è§„åˆ™: {rule.rule_id}")
                        else:
                            # æ·»åŠ æ–°è§„åˆ™
                            database.add_rule(rule)
                            added_count += 1
                            print(f"â• æ·»åŠ è§„åˆ™: {rule.rule_id}")
                    
                    print(f"ğŸ“Š åˆå¹¶ç»“æœ: æ–°å¢ {added_count} æ¡ï¼Œæ›´æ–° {updated_count} æ¡")
                    
                except Exception as e:
                    print(f"âš ï¸ åˆå¹¶åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")
                    if args.verbose:
                        import traceback
                        traceback.print_exc()
            
            # å¦‚æœå¯ç”¨éªŒè¯ï¼ŒéªŒè¯å¯¼å…¥çš„è§„åˆ™
            if args.validate:
                print("ğŸ” æ­£åœ¨éªŒè¯å¯¼å…¥çš„è§„åˆ™...")
                
                valid_count = 0
                invalid_count = 0
                
                for rule in rules:
                    try:
                        # ç®€å•éªŒè¯ï¼šæ£€æŸ¥å¿…éœ€å­—æ®µ
                        if not rule.rule_id or not rule.name or not rule.rules:
                            print(f"âŒ è§„åˆ™éªŒè¯å¤±è´¥: {rule.rule_id} - ç¼ºå°‘å¿…éœ€å­—æ®µ")
                            invalid_count += 1
                        else:
                            print(f"âœ… è§„åˆ™éªŒè¯é€šè¿‡: {rule.rule_id}")
                            valid_count += 1
                    except Exception as e:
                        print(f"âŒ è§„åˆ™éªŒè¯å¤±è´¥: {rule.rule_id} - {e}")
                        invalid_count += 1
                
                print(f"ğŸ“Š éªŒè¯ç»“æœ: é€šè¿‡ {valid_count} æ¡ï¼Œå¤±è´¥ {invalid_count} æ¡")
            
            # æ˜¾ç¤ºå¯¼å…¥æ‘˜è¦
            summary = importer.get_import_summary()
            
            print("\n" + "="*60)
            print("ğŸ“Š å¯¼å…¥æ‘˜è¦:")
            print(f"  æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
            print(f"  æˆåŠŸå¯¼å…¥: {summary['successful_imports']}")
            print(f"  å¯¼å…¥å¤±è´¥: {summary['failed_imports']}")
            print(f"  æˆåŠŸç‡: {summary['success_rate']:.1%}")
            print(f"  æ€»è§„åˆ™æ•°: {len(rules)}")
            
            # æŒ‰æ ¼å¼ç»Ÿè®¡
            format_stats = {}
            for log_entry in summary['import_log']:
                if log_entry['status'] == 'success':
                    file_path = Path(log_entry['file'])
                    ext = file_path.suffix.lower()
                    format_name = {
                        '.md': 'Markdown',
                        '.markdown': 'Markdown', 
                        '.yaml': 'YAML',
                        '.yml': 'YAML',
                        '.json': 'JSON'
                    }.get(ext, 'Unknown')
                    
                    format_stats[format_name] = format_stats.get(format_name, 0) + 1
            
            if format_stats:
                print("\nğŸ“ æŒ‰æ ¼å¼ç»Ÿè®¡:")
                for format_name, count in format_stats.items():
                    print(f"  {format_name}: {count} ä¸ªæ–‡ä»¶")
            
            # ä¿å­˜å¯¼å…¥æ—¥å¿—
            if args.log:
                log_path = Path(args.log)
                importer.save_import_log(log_path)
                print(f"ğŸ“ å¯¼å…¥æ—¥å¿—å·²ä¿å­˜: {log_path}")
            
            return 0 if summary['failed_imports'] == 0 else 1
            
        except Exception as e:
            logger.error(f"å¯¼å…¥è§„åˆ™å¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            return 1


async def main() -> int:
    """ä¸»å…¥å£å‡½æ•°"""
    cli = CLI()
    return await cli.run(sys.argv[1:])


def sync_main() -> int:
    """åŒæ­¥ä¸»å…¥å£å‡½æ•°"""
    return asyncio.run(main())


if __name__ == "__main__":
    sys.exit(sync_main())